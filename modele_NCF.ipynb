{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>rating</th>\n",
       "      <th>userId</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>animation friendship toys animation Disney Pix...</td>\n",
       "      <td>3.893508</td>\n",
       "      <td>80450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>animals based on a book fantasy magic board ga...</td>\n",
       "      <td>3.278179</td>\n",
       "      <td>72515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "      <td>sequel moldy old old age old men wedding old p...</td>\n",
       "      <td>3.171271</td>\n",
       "      <td>84638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "      <td>characters chick flick girl movie characters c...</td>\n",
       "      <td>2.868395</td>\n",
       "      <td>18411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "      <td>family pregnancy wedding 4th wall aging baby d...</td>\n",
       "      <td>3.076957</td>\n",
       "      <td>15657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  imdbId   tmdbId  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  114709    862.0   \n",
       "1                   Adventure|Children|Fantasy  113497   8844.0   \n",
       "2                               Comedy|Romance  113228  15602.0   \n",
       "3                         Comedy|Drama|Romance  114885  31357.0   \n",
       "4                                       Comedy  113041  11862.0   \n",
       "\n",
       "                                                 tag    rating  userId  \\\n",
       "0  animation friendship toys animation Disney Pix...  3.893508   80450   \n",
       "1  animals based on a book fantasy magic board ga...  3.278179   72515   \n",
       "2  sequel moldy old old age old men wedding old p...  3.171271   84638   \n",
       "3  characters chick flick girl movie characters c...  2.868395   18411   \n",
       "4  family pregnancy wedding 4th wall aging baby d...  3.076957   15657   \n",
       "\n",
       "   popularity  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#moovielens \n",
    "movies = pd.read_csv('movies.csv') \n",
    "links = pd.read_csv('links.csv')\n",
    "tags = pd.read_csv('tags.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "tags['tag'] = tags['tag'].fillna('')\n",
    "\n",
    "#concatener les tags\n",
    "movies_avec_links = pd.merge(movies, links, on='movieId', how='left')  #merge le dasaset movies et links\n",
    "movie_tags = tags.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index() #groupby le dataset tags par movieId et concatener les tags\n",
    "\n",
    "# merger les dataframes movies_with_links et movie_tags\n",
    "movies_with_ratings = pd.merge(movies_avec_links, ratings, on='movieId', how='left') #merge le dataset movies_with_links et ratings\n",
    "\n",
    "# Calculer la moyenne des ratings\n",
    "mean_ratings = movies_with_ratings.groupby('movieId')['rating'].mean().reset_index() #groupby le dataset movies_with_ratings par movieId et calculer la moyenne des ratings\n",
    "\n",
    "# merger les dataframes\n",
    "data = pd.merge(movies_avec_links, movie_tags, on='movieId', how='left')\n",
    "data = pd.merge(data, mean_ratings, on='movieId', how='left')\n",
    "\n",
    "#ajouter une colone user_id\n",
    "data['userId'] = np.random.randint(1, 86537, data.shape[0])\n",
    "\n",
    "#ajouter une colonne popularity\n",
    "data['populaire'] = data['rating'].groupby(data['movieId']).transform('count')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#nombre de doublons\n",
    "print(data.duplicated().sum())   #pas de doublos \n",
    "\n",
    "# ============= pas de valeurs manquantes ni de doublons =============\n",
    "data.dropna(subset=['tmdbId'], inplace=True)\n",
    "#rempcer les valeurs manquantespar \"\"\n",
    "data['tag'] = data['tag'].fillna('')\n",
    "data['rating'] = data['rating'].fillna(data['rating'].mean())\n",
    "\n",
    "#====netoyyer les colonnes =================================================\n",
    "data['genres'] = data['genres'].str.replace('|', ' ')\n",
    "data['rating'] = pd.to_numeric(data['rating'], errors='coerce')\n",
    "data['title'] = data['title'].str.strip() \n",
    "data['tag'] = data['tag'].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>tag</th>\n",
       "      <th>rating</th>\n",
       "      <th>userId</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure Children Fantasy</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>animals based on a book fantasy magic board ga...</td>\n",
       "      <td>0.342364</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy Romance</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "      <td>sequel moldy old old age old men wedding old p...</td>\n",
       "      <td>0.204515</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy Drama Romance</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357.0</td>\n",
       "      <td>characters chick flick girl movie characters c...</td>\n",
       "      <td>-0.186019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862.0</td>\n",
       "      <td>family pregnancy wedding 4th wall aging baby d...</td>\n",
       "      <td>0.082905</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy Romance</td>\n",
       "      <td>114319</td>\n",
       "      <td>11860.0</td>\n",
       "      <td>based on a play harrison ford paris romance si...</td>\n",
       "      <td>0.463777</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title                      genres  \\\n",
       "1        1                      Jumanji (1995)  Adventure Children Fantasy   \n",
       "2        2             Grumpier Old Men (1995)              Comedy Romance   \n",
       "3        3            Waiting to Exhale (1995)        Comedy Drama Romance   \n",
       "4        4  Father of the Bride Part II (1995)                      Comedy   \n",
       "6        6                      Sabrina (1995)              Comedy Romance   \n",
       "\n",
       "   imdbId   tmdbId                                                tag  \\\n",
       "1  113497   8844.0  animals based on a book fantasy magic board ga...   \n",
       "2  113228  15602.0  sequel moldy old old age old men wedding old p...   \n",
       "3  114885  31357.0  characters chick flick girl movie characters c...   \n",
       "4  113041  11862.0  family pregnancy wedding 4th wall aging baby d...   \n",
       "6  114319  11860.0  based on a play harrison ford paris romance si...   \n",
       "\n",
       "     rating  userId  popularity  \n",
       "1  0.342364       1           1  \n",
       "2  0.204515       2           1  \n",
       "3 -0.186019       3           1  \n",
       "4  0.082905       4           1  \n",
       "6  0.463777       6           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=================mapping pour le modele NCF=========================\n",
    "#mapping des userId\n",
    "user_id_mapping = {id:i for i, id in enumerate(data['userId'].unique())} #créer un dictionnaire avec les userId et leur index\n",
    "data['userId'] = data['userId'].map(user_id_mapping)\n",
    "#mapping des movieId\n",
    "movie_id_mapping = {id:i for i, id in enumerate(data['movieId'].unique())}\n",
    "data['movieId'] = data['movieId'].map(movie_id_mapping)\n",
    "\n",
    "#==Normaliser les colonnes rating et popularity =======================\n",
    "scaler = StandardScaler()\n",
    "data['rating'] = scaler.fit_transform(data['rating'].values.reshape(-1, 1))\n",
    "\n",
    "data = data[(data['rating'] >= -1) & (data['rating'] <= 1)] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - loss: 0.0657\n",
      "Epoch 2/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 53ms/step - loss: 0.0643\n",
      "Epoch 3/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 58ms/step - loss: 0.0632\n",
      "Epoch 4/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - loss: 0.0585\n",
      "Epoch 5/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - loss: 0.0403\n",
      "Epoch 6/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 51ms/step - loss: 0.0251\n",
      "Epoch 7/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 51ms/step - loss: 0.0169\n",
      "Epoch 8/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 53ms/step - loss: 0.0123\n",
      "Epoch 9/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 52ms/step - loss: 0.0094\n",
      "Epoch 10/10\n",
      "\u001b[1m708/708\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 52ms/step - loss: 0.0072\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Loss sur les notes originales : 0.37955552479643356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.models import Model , load_model  # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "\n",
    "# Normalisation des notes entre 0 et 1\n",
    "scaler = MinMaxScaler()\n",
    "data['rating'] = scaler.fit_transform(data['rating'].values.reshape(-1, 1))\n",
    "\n",
    "# Division des données\n",
    "x = data[['userId', 'movieId']]\n",
    "y = data['rating']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construction du modèle\n",
    "user_input = Input(shape=(1,)) #créer une couche d'entrée pour les userId\n",
    "movie_input = Input(shape=(1,)) #créer une couche d'entrée pour les movieId\n",
    "\n",
    "user_embedding = Embedding(len(user_id_mapping), 32)(user_input) #créer une couche d'embedding pour les userId avec 32 neurones\n",
    "movie_embedding = Embedding(len(movie_id_mapping), 32)(movie_input) #créer une couche d'embedding pour les movieId \n",
    "\n",
    "user_flatten = Flatten()(user_embedding) #applatir la couche d'embedding des userId\n",
    "movie_flatten = Flatten()(movie_embedding) #applatir la couche d'embedding des movieId\n",
    "\n",
    "conc = Concatenate()([user_flatten, movie_flatten]) #concaténer les couches d'embedding\n",
    "\n",
    "dense = Dense(128, activation='relu')(conc) #créer une couche dense de 128 neurones avec une fonction d'activation relu\n",
    "dense = Dropout(0.5)(dense) #ajouter une couche de dropout avec un taux de 0.5 pour éviter le surapprentissage\n",
    "dense = Dense(64, activation='relu')(dense) #créer une couche dense de 64 neurones avec une fonction d'activation relu\n",
    "dense = Dropout(0.5)(dense)\n",
    "dense = Dense(32, activation='relu')(dense) #créer une couche dense de 32 neurones avec une fonction d'activation relu\n",
    "sortie = Dense(1, activation='sigmoid')(dense)  #créer une couche de sortie avec une fonction d'activation sigmoid\n",
    "\n",
    "model = Model(inputs=[user_input, movie_input], outputs=sortie)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit([x_train['userId'], x_train['movieId']], y_train, batch_size=64, epochs=10, verbose=1)\n",
    "\n",
    "# Prédiction et inversion de la normalisation\n",
    "y_pred_normalized = model.predict([x_test['userId'], x_test['movieId']])\n",
    "y_pred = scaler.inverse_transform(y_pred_normalized)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Top 5 Movies (IDs): [64285 27716 34292  4585  6428]\n",
      "Top 5 Ratings: [0.900386   0.88814247 0.88744164 0.8863874  0.8735525 ]\n",
      "Top 5 Movies (Titles): ['Dream Team, The (1989)' 'Two Mules for Sister Sara (1970)'\n",
      " 'Green Butchers, The (Grønne slagtere, De) (2003)' 'Hardware (1990)'\n",
      " \"Wallace and Gromit in 'A Matter of Loaf and Death' (2008)\"]\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # type: ignore\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler # type: ignore\n",
    "\n",
    "# Charger le modèle\n",
    "model = load_model('model_NCF.h5')\n",
    "\n",
    "\n",
    "def top_5_recommandation(user, model, movie_ids, valid_movie_ids, scaler):\n",
    "    # Filtrer les IDs pour qu'ils soient valides\n",
    "    movie_ids = [movie for movie in movie_ids if movie in valid_movie_ids]  # Ne garder que les IDs valides\n",
    "\n",
    "    # Prédictions\n",
    "    user_array = np.array([user] * len(movie_ids))\n",
    "    movie_array = np.array(movie_ids)\n",
    "    predictions = model.predict([user_array, movie_array])\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "    # Trier les résultats\n",
    "    indices = np.argsort(predictions.flatten())[::-1]\n",
    "    top_5 = indices[:5]\n",
    "    top_5_movies = movie_array[top_5]\n",
    "    top_5_ratings = predictions.flatten()[top_5]\n",
    "\n",
    "    return top_5_movies, top_5_ratings\n",
    "\n",
    "# Exemple : Recommandations pour un utilisateur\n",
    "user_id = 1  # ID de l'utilisateur\n",
    "movie_ids = data['movieId'].unique()  # Liste des films disponibles\n",
    "movies_df = pd.read_csv('movies.csv')  # Charger le fichier movies.csv\n",
    "valid_movie_ids = movies_df['movieId'].values  # IDs dans movies.csv\n",
    "\n",
    "# Obtenir les recommandations\n",
    "top_5_movies, top_5_ratings = top_5_recommandation(user_id, model, movie_ids, valid_movie_ids, scaler)\n",
    "\n",
    "# Mapper les `movieId` recommandés aux titres\n",
    "nom_movies = movies_df[movies_df['movieId'].isin(top_5_movies)]['title'].values\n",
    "\n",
    "\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Top 5 Movies (IDs):\", top_5_movies)\n",
    "print(\"Top 5 Ratings:\", top_5_ratings)\n",
    "print(\"Top 5 Movies (Titles):\", nom_movies)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Precision: 0.5189518787079763\n",
      "Recall: 0.6262304862284975\n",
      "RMSE: 0.30809455379201206\n"
     ]
    }
   ],
   "source": [
    "#evaluer le modele \n",
    "from sklearn.metrics import precision_score, recall_score, mean_squared_error # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "# Fonction pour évaluer la précision et le rappel\n",
    "def evaluate_model(model, x_test, y_test, threshold=0.5):\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = predictions.flatten()\n",
    "    y_pred = (predictions > threshold).astype(int)\n",
    "    y_true = (y_test > threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Fonction pour calculer le RMSE\n",
    "def calculate_rmse(model, x_test, y_test):\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = predictions.flatten()\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Évaluer le modèle\n",
    "precision, recall = evaluate_model(model, [x_test['userId'], x_test['movieId']], y_test)\n",
    "rmse = calculate_rmse(model, [x_test['userId'], x_test['movieId']], y_test)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"RMSE: {rmse}\") #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
